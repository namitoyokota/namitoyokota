# Main Memory

Date: April 5, 2020
Section: Chapter 8
Type: Textbook

## extra info
**overhead** - the processing time required by system software

## 8.1 Background
basic hardware
- main memory and the register built into the processor itself are the only general-purpose storage that CPU can access directly
- to make sure that each process has a separate memory space, we can use provide a protection by using two registers.
- The **base register** holds the smallest legal physical memory address
- The **limit register** specifies the size of the range

address binding
- a program resides on a disk as a binary executable file. to be executed, the program must be brought into memory and placed within a process. address binding the process right after that
- classically, the binding of instructions and data to memory addresses can be done at any step along the way
  - **compile time** - if you know at compile time where the process will reside in memory, then absolute code can be generated
  - **load time** - if it is not known at compile time where the process will reside in memory, then the compile must generate relocatable code
  - **execution time** - if the process can be moved during its execution from one memory segment to another, then binding must be delayed until run time

logical vs physical address space
- new terms and concepts
  - an address generated by the CPU is commonly referred to as a logical address
  - an address seen by the memory unit is commonly referred to as a physical address
  - the set of all logical addresses generated by a program is a logical address space
  - the set of all physical addresses corresponding to these logical addresses is a physical address space
  - the run-time mapping frmo virtual to physical addresses is done by a hardware device called the memory-management unit (mmu)
  - the base register during this process is now called a relocation register
- easier to think this way!
  - we now have two different types of addresses:
    - logical addresses: in the range 0 to max
    - physical addresses: in the range R+0 to R+max for a base value R

dynamic loading
- dynamic loading is a loading mechanism where the routine is not loaded until it is called

- it can be used to obtain better memory-space utilization
  - dynamic linking and shared libraries
  - dynamically linked libraries are system libraries that are linked to use programs when the programs are run
  - in static linking, system libraries are treated like any other object module and are combined by the loader into the binary program image
- the stub is a small piece of code that indicates how to locate the appropriate memory-resident library routine or how to load the library if the routine is not already present
  - shared libraries is a system where a library may be replaced by a new version, and all programs that reference the library will automatically use the new version.

## 8.2 Swapping
intro
- swapping in a process of swapping out a process temporarily to a backing store and then brought back into memory for continued execution.
- this allows the total physical address space of all processes to exceed the real physical memory of the system, thus increasing the degree of multiprogramming in a system

standard swapping
- standard swapping is the method described above. it involves moving processes between main memory and a backing store. the backing store is commonly a fast disk.
- the system maintain a ready queue consisting of all processes whose memory images are on the backing store or in memory and are ready to run
- problem: the process must be completely idle
  1. never swap a process with pending io
  2. execute io operations only into operating-system buffers
- note that this double buffering adds overhead
  - swapping on mobile systems
  - problem: most mobile systems do not support swapping
    - iOS asks applications to voluntarily relinquish allocated memory
    - Android may terminate a process if insufficient free memory is available

## 8.3 Contiguous Memory Allocation
- intro
  - contiguous memory allocation is a method where each process is contained in a single section of memory that is contiguous to the section containing the next process
    - memory protection
      - transient operating-system code is code and data in memory with space that might be able to be used for other purposes
    - memory allocation
      - multiple-partition method is a method by diving memory into several fixed-sized partitions where each partition may contain exactly one process. When a partition is free, a process is selected from the input queue and is loaded into the free partition. When the process terminates, the partition becomes available for another process
      - in a variable-partition scheme, the operating system keeps a table indicating which parts of memory are available and which are occupied.
      - one large block of available memory is called a hole
      - dynamic storage-allocation problem: concerns how to satisfy a request of size n from a list of free holes
      - first fit: allocate the first hole that is big enough
      - best fit: allocate the smallest hole that is big enough
      - worst fit: allocate the largest hole
    - fragmentation
      - external fragmentation exists when there is enough total memory space to satisfy a request but the available spaces are not contiguous: storage is fragmented into a large number of small holes
      - solution: compaction where you shuffle the memory contents so as to place all free memory together in one large block
      - solution: permit the logical address space of the processes to be noncontiguous, thus allowing a process to be allocated physical memory wherever such memory is available
      - internal fragmentation exists when there is unused memory that is internal to a partition

## 8.4 Segmentation
- basic method
  - segmentation is a memory-management scheme that supports the programmer's view of memory as a collection of variable-sized segments, with no necessary ordering among the segments
- segmentation hardware
  - segment table is used to map two-dimensional user-defined addresses into one-dimensional physical addresses
- each entry in the segment table has a segment base and a segment limit
  - segment base contains the starting physical address where the segment resides in memory, and the segment limit specifies the length of the segment

## 8.5 Paging
- intro
  - paging is another memory-management scheme that on top of the segmentation advantage, avoids external fragmentation and the need for compaction
- basic method
  - the basic method for implementing paging involves breaking physical memory into fixed-sized blocks called frames and breaking logical memory into blocks of the same size called pages
  - every address generated by the cpu is divided into two parts: page number and page offset
  - the page number is used as an index into a page table. the page table contains the base address of each page in physical memory
  - the frame table has one entry for each physical page frame, indicating whether the latter is free or allocated and, if it is allocated, to which page of which process or processes
- hardware support
  - one simple implementation of the page table is done through a set of dedicated registers.
  - for a larger page table, the page table can be kept in main memory, and a page-table base register (PTBR) pointing to the page table
  - the standard implementation is using a special, small, fast-lookup hardware cache called a translation look-aside buffer (TLB)
  - the TLB is associate, high-speed memory
  - each entry in the TLB consists of two parts: a key and a value
  - if the page number is not found in the TLB (known as a TLB miss), a memory reference to the page table must be made
  - sine TLBs allow certain entries to be wired down, meaning that they cannot be removed from the TLB
  - some TLBs store address-space identifies (ASIDs) in each TLB entry. the ASID uniquely identifies each process and is used to provide address-space protection for that process
  - the percentage of times that the page number of interest is found in the TLB is called the hit ratio
- protection
  - valid-invalid bit is an additional bit that is generally attached to each entry in the page table
  - when this bit is set to *valid*, the associated page is in the process's logical address space and is thus a legal page
  - when the bit is set to *invalid*, the page is not in the process's logical address space
  - page-table length register (PTLR) is a hardware used to indicate the size of the page table
- shared pages
  - an advantage of paging is the possibility of sharing common code
  - if the code is reentrant code (or pure code), it can be shared

## 8.6 Structure of the Page Table
- hierarchical paging
  - hierarchical paging uses a two-level paging algorithm, in which the page table itself is also paged
  - because address translation works from the outer page table inward, this scheme is also known as a forward-mapped page table
- hashed page tables
  - hashed page table is a common approach for handling address spaces larger than 32 bits with the hash value being the virtual page number
    - each entry in the hash table contains a linked list of elements that hash to the same location
    - each element consists of three fields
      1. the virtual page number
      2. the value of the mapped page frame
      3. a pointer to the next element in the linked list
    - clustered page tables is variation of the above scheme that is useful for 64-bit address space
      - clustered page tables are particularly useful for sparse address spaces, where memory references are noncontiguous and scattered throughout the address space
    - inverted page tables
      - inverted page table solves the problem of each page table consisting of millions of entries
      - an inverted page table has one entry for each real page of memory. each entry consists of the virtual address of the page stored in that real memory location with information about the process that owns that page
